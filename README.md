# ğŸ“Œ AdventureWorks Data Warehouse Project

This project demonstrates the design and implementation of an **end-to-end, production-style Data Warehouse** using the AdventureWorks OLTP dataset.

The goal is to build a **scalable, analytics-ready DWH** that centralizes operational data, enables efficient reporting, and reflects real-world data engineering and dimensional modeling practices.

The project focuses on **architectural clarity, SQL-based ETL development, and clean analytical modeling**, making it suitable as a portfolio-quality implementation.

---

## ğŸ¯ Project Objectives

The project is considered successful when the following outcomes are achieved:

- **Dimensional Data Model:** A fully defined **Star Schema** covering Sales, Products, Customers, and Geography domains.
- **Data Pipeline:** Reliable **OLTP â†’ Staging â†’ DWH â†’ Mart** data flow.
- **Data Quality:** Clean, conformed, and analytics-ready datasets.
- **Performance:** Query-optimized warehouse design supporting reporting and aggregations.
- **Documentation:** Clear technical documentation including **ERDs, star schema diagrams, and data lineage**.
- **Reproducibility:** A fully reproducible setup using **version-controlled SQL scripts**.

---

## ğŸ—ï¸ Architecture Overview

The solution follows a layered warehouse architecture:

1. **OLTP Source:** AdventureWorks transactional database.
2. **Staging Layer:** Raw data ingestion with separated extraction and loading logic.
3. **Data Warehouse (DWH):**
    - **Bronze:** Minimally transformed raw data.
    - **Silver:** Cleaned, standardized, and conformed data.
    - **Gold:** Dimensional models (facts & dimensions).
4. **Data Marts & Analytics:** Business-focused analytical views and Power BI datasets.

> **Note:** Extraction queries are executed on the OLTP source system, but they are owned and versioned under the staging layer as part of the ETL responsibility.

---

## ğŸ“‚ Repository Structure

> â”œâ”€â”€ config/  
> â”‚   â”œâ”€â”€ mappings/ # Mapping files between source and DWH  
> â”‚   â”œâ”€â”€ environments/ # Environment-specific configs  
> â”‚   â””â”€â”€ dq_rules/ # Data quality rules and definitions  
> â”œâ”€â”€ docs/  
> â”‚   â”œâ”€â”€ architecture/ # ERDs, star schema diagrams  
> â”‚   â”œâ”€â”€ modeling/ # Dimensional modeling docs  
> â”‚   â””â”€â”€ dq_reports/ # Data profiling and quality reports  
> â”œâ”€â”€ src/  
> â”‚   â”œâ”€â”€ infrastructure/ # Database & schema setup scripts  
> â”‚   â”œâ”€â”€ oltp_exploration/ # Source system analysis & profiling  
> â”‚   â”œâ”€â”€ staging/  
> â”‚   â”‚   â”œâ”€â”€ extract/ # OLTP source extraction logic  
> â”‚   â”‚   â””â”€â”€ load/ # Staging table definitions and load scripts  
> â”‚   â”œâ”€â”€ dwh/  
> â”‚   â”‚   â”œâ”€â”€ bronze/ # Minimally transformed raw data  
> â”‚   â”‚   â”œâ”€â”€ silver/ # Cleaned, standardized, conformed data  
> â”‚   â”‚   â””â”€â”€ gold/ # Dimensional models (facts & dimensions)  
> â”‚   â”œâ”€â”€ dq/ # Data quality stored procedures / checks  
> â”‚   â”œâ”€â”€ pipelines/ # Orchestration placeholders (ADF / Airflow)  
> â”‚   â””â”€â”€ test/ # Validation, unit, integration, regression tests  
> â””â”€â”€ README.md

---

## ğŸ› ï¸ Tooling & Technologies

- **Database:** Microsoft SQL Server
- **ETL / ELT:** SQL-based pipelines (Stored Procedures, Views, Batch Jobs)
- **Modeling:** Kimball Dimensional Modeling (Star Schema)
- **BI & Analytics:** Power BI
- **Version Control:** Git & GitHub
- **Documentation:** Markdown, Mermaid.js, profiling reports

---

## âš ï¸ Constraints & Assumptions

### Assumptions
- AdventureWorks OLTP database is available and restored.
- Batch processing is sufficient (no streaming requirements).
- Data volumes remain within SQL Server processing limits.

### Constraints
- Local development environment.
- Source system structure cannot be modified.
- Scope intentionally focuses on the **Sales domain** to maintain clarity and depth.

---

## ğŸ“˜ Additional Documentation

- Detailed step-by-step project planning, design decisions, and implementation notes are maintained in **Notion** and referenced where applicable.

---

**Final Note:** This project is designed to reflect **real-world data warehouse development practices**, emphasizing **clarity, maintainability, and architectural discipline**.